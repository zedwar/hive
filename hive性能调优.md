在大数据领域，分布式计算和分布式存储会消耗大量的磁盘I/O和网络I/O资源，这部分资源往往成为了大数据作业的瓶颈。在运行案例1.3时观察集群资源的运行情况，将会发现CPU使用率很少，磁盘和网络读/写会变得很高，所以优化的焦点就集中在如何降低作业对I/O资源的消耗上。MR任务有一个缺点，即启动一次作业需要多次读/写磁盘，因为MR会将中间结果写入磁盘，而且为了保障磁盘的读写效率和网络传输效率，会进行多次排序。
客户端提交SQL作业到HiveServer2, HiveServer2会根据用户提交的SQL 作业及数据库中现有的元数据信息生成一份可供计算引擎执行的计划。每个执行计划对应若干MapReduce作业，Hive会将所有的MapReduce作业都一一提交到YARN中，由YARN去负责创建MapReduce作业对应的子任务任务，并协调它们的运行。YARN创建的子任务会与HDFS进行交互，获取计算所需的数据，计算完成后将最终的结果写入HDFS或者本地。
从整个Hive运行作业的过程，我们可以知道Hive自身主要包含如下3个部分：
第一部分是客户端（client）。Hive支持多种客户端的连接，包括beeline、jdbc、thrift和HCatalog。早期的Hive Command Line（CLI）由于可以直接操作HDFS存储的数据，权限控制较为困难，支持的用户数有限，已经被废弃。
第二部分是HiveServer2。替代早期的HiveServer，提供了HTTP协议的Web服务接口和RPC协议的thrift服务接口，使得Hive能够接收多种类型客户端的并发访问，并将客户端提交的SQL进行编译转化可供计算引擎执行的作业。借助于HiveServer2, Hive可以做到更为严格的权限验证。在实际使用中需要注意HiveServre2服务Java堆大小的设置，默认情况下是50MB，在查询任务增多的情况下，容器发生内存溢出，导致服务崩溃，用户访问不了Hive。
第三部分是元数据及元数据服务。Hive的元数据记录了Hive库内对象的信息，包括表的结构信息、分区结构信息、字段信息及相关的统计信息等。
Hive的元数据保存在Hive的metastore数据中，里面记录着Hive数据库、表、分区和列的一些当前状态信息，通过收集这些状态信息，可以帮助我们更好地监控Hive 数据库当前的状态，提前感知可能存在的问题；可以帮助基于成本代价的SQL 查询优化，做更为正确的自动优化操作。
Hive的元数据主要分为5个大部分：数据库相关的元数据、表相关的元数据、分区相关的元数据、文件存储相关的元数据及其他。
DBS：描述Hive中所有的数据库库名、存储地址（用字段DB_LOCATION_URI表示）、拥有者和拥有者类型。
DATABASE_PARAMS：描述数据库的属性信息（DBPROPERTIES）。例如，创建一个带有库属性信息的库
DB_PRIVS：描述数据库的权限信息。
FUNCS：记录用户自己编写的函数信息（UDF），包括该函数的函数名、对应的类名和创建者等信息。用户可以通过命令“create function函数名…”来创建自定义函数。
FUNCS_RU：记录自定义函数所在文件的路径，例如使用Java编写Hive的自定义函数,FUNCS_RU表会记录该函数所在JAR包的HDFS存储位置，以及该JAR包引用的其他JAR包信息。
TBLS：记录Hive数据库创建的所有表，包含表所属的数据库、创建时间、创建者和表的类型（包括内部表、外部表、虚拟视图等）。在Hive中使用命令“desc formatted表名”，查看Detailed Table Information一节的信息
TABLE_PARAMS：表的属性信息，对应的是创建表所指定的TBLPROPERTIES内容或者通过收集表的统计信息。收集表的统计信息可以使用如下的命令：表的统计信息一般包含表存储的文件个数（numFiles）、总文件大小（totalSize）、表的总行数（numRows）、分区数（numPartitions）和未压缩的每行的数据量（rawDataSize）等。TAB_COL_STATS：表中列的统计信息，包括数值类型的最大和最小值，如LONG_LOW_VALUE、LONG_HIGH_VALUE、DOUBLE_HIGH_VALUE、DOUBLE_LOW_VALUE、BIG_DECIMAL_LOW_VALUE、BIG_DECIMAL_HIGHT_VALUE、空值的个数、列去重的数值、列的平均长度、最大长度，以及值为TRUE/FALSE的个数等。TBL_PRIVS：表或者视图的授权信息，包括授权用户、被授权用户和授权的权限等。TBL_COL_PRIVS：表或者视图中列的授权信息，包括授权用户、被授权的用户和授权的权限等。PARTITION_KEYS：表的分区列。IDXS:Hive中索引的信息，Hive 3.0已经废弃。
MapReduce是一种计算引擎，也是一种编程模型。MapReduce提供了两个编程接口，即Map和Reduce，让用户能够在此基础上编写自己的业务代码，而不用关心整个分布式计算框架的背后工作。这样的好处是能够让开发人员专注自己的业务领域，缺点是如果发生Map/Reduce业务代码以外的性能问题，开发人员通常束手无策。
MapReduce 会经历作业输入（Input）、业务处理接口Map、Map到Reduce之间数据传输的环节Shuffle、业务处理接口Reduce和作业输出（Output）五大环节。








































































































































































































